# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Set style for visualizations
sns.set(style="whitegrid")
plt.style.use('seaborn')

# ======================
# PROJECT 1: GENERAL EDA
# ======================

def load_and_clean_data(filepath):
    """Load and clean the dataset"""
    try:
        # Load dataset
        df = pd.read_csv(filepath)
        
        # Data cleaning
        print("\n=== Initial Data Summary ===")
        print(f"Shape: {df.shape}")
        print("\nMissing values before cleaning:")
        print(df.isnull().sum())
        
        # Handle missing values
        df = df.dropna()  # or use df.fillna() with appropriate values
        
        # Remove duplicates
        df = df.drop_duplicates()
        
        # Remove outliers (example for numerical columns)
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            q1 = df[col].quantile(0.25)
            q3 = df[col].quantile(0.75)
            iqr = q3 - q1
            df = df[(df[col] >= q1 - 1.5*iqr) & (df[col] <= q3 + 1.5*iqr)]
        
        print("\n=== After Cleaning ===")
        print(f"New shape: {df.shape}")
        print("\nMissing values after cleaning:")
        print(df.isnull().sum())
        
        return df
    
    except Exception as e:
        print(f"Error loading data: {e}")
        return None

def perform_eda(df):
    """Perform exploratory data analysis"""
    print("\n=== EDA Results ===")
    
    # Basic statistics
    print("\nDescriptive Statistics:")
    print(df.describe())
    
    # Correlation analysis
    print("\nCorrelation Matrix:")
    print(df.corr())
    
    # Visualization
    plt.figure(figsize=(12, 8))
    
    # Histograms for numerical columns
    print("\nPlotting distributions...")
    df.hist(bins=20, figsize=(15, 10))
    plt.tight_layout()
    plt.savefig('distributions.png')
    plt.close()
    
    # Heatmap
    plt.figure(figsize=(10, 8))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0)
    plt.title('Correlation Heatmap')
    plt.tight_layout()
    plt.savefig('correlation_heatmap.png')
    plt.close()
    
    # Pairplot for selected columns
    if len(df.columns) > 5:  # Avoid too many columns for pairplot
        cols = df.select_dtypes(include=[np.number]).columns[:5]
        sns.pairplot(df[cols])
        plt.savefig('pairplot.png')
        plt.close()

# ==============================
# PROJECT 2: SALES PERFORMANCE ANALYSIS
# ==============================

def analyze_sales(df, target_col='Sales'):
    """Analyze sales performance and build predictive model"""
    print("\n=== Sales Performance Analysis ===")
    
    # Time series analysis if date column exists
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        
        # Monthly sales trend
        monthly_sales = df[target_col].resample('M').sum()
        
        plt.figure(figsize=(12, 6))
        monthly_sales.plot(title='Monthly Sales Trend')
        plt.ylabel('Sales')
        plt.tight_layout()
        plt.savefig('monthly_sales_trend.png')
        plt.close()
    
    # Sales by category/region
    categorical_cols = [col for col in df.columns if df[col].dtype == 'object']
    
    for col in categorical_cols:
        plt.figure(figsize=(10, 6))
        sns.barplot(x=col, y=target_col, data=df, estimator=np.sum)
        plt.title(f'Sales by {col}')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(f'sales_by_{col}.png')
        plt.close()
    
    # Predictive modeling
    print("\nBuilding predictive model...")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    X = df[numeric_cols].drop(target_col, axis=1)
    y = df[target_col]
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    # Evaluate model
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    print("\nModel Performance:")
    print(f"Mean Squared Error: {mse:.2f}")
    print(f"R-squared: {r2:.2f}")
    
    # Feature importance
    importance = pd.DataFrame({
        'Feature': X.columns,
        'Coefficient': model.coef_
    }).sort_values('Coefficient', ascending=False)
    
    print("\nFeature Importance:")
    print(importance)
    
    return model

# ======================
# MAIN EXECUTION
# ======================

if __name__ == "__main__":
    # Example usage
    print("DATA ANALYSIS AND DATA SCIENCE WITH PYTHON")
    print("TASK - 2: Exploratory Data Analysis (EDA)\n")
    
    # Load and clean data
    data_path = 'sales_data.csv'  # Replace with your file path
    df = load_and_clean_data(data_path)
    
    if df is not None:
        # Perform EDA
        perform_eda(df)
        
        # Sales performance analysis
        model = analyze_sales(df)
        
        print("\n=== Analysis Complete ===")
        print("Visualizations saved as PNG files")
        print("Model trained and evaluated")
    else:
        print("Failed to load data. Please check the file path.")
